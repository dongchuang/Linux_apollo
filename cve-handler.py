#===============================================================================
# README:
# depends on xlwt, to install it on ubuntu: sudo apt-get install python-xlwt
# need a PACKAGE_LIST_FILE file
#
# will generate 2 files: twiki_table_patchlist.txt,
# and WRLinuxVERSION-CUSTOMER-CVE-List-YEARMONTH.xls
#===============================================================================

import urllib
import copy
from HTMLParser import HTMLParser

# initial keys in cve dictionary
keys = ["Number",
        "JiraID",
        "Package",
        "Priority",
        "Published",
        "ACK",
        "CommittedDate",
        "FixedDate",
        "ResponseDays",
        "ReliefDays",
        "Status",
        "RCPL",
        "Developer"]
cves = []
cve = {}

WRL_CVE_URL = "http://ala-lpd-susbld.wrs.com/cgi-bin/cve_slt_ver.cgi?ver=60&year=2015"
PACKAGE_LIST_FILE = "packages-list.txt"
#===============================================================================

class WrlCveHTMLParser(HTMLParser):
    global cves
    global cve
    data_num = 0
    tag_stack = []
    target_tag_stack = ["html", "table"]


    def is_interested(self):
        if (len(self.tag_stack) < len(self.target_tag_stack)):
            return False

        for i in range(len(self.target_tag_stack)):
            if (self.target_tag_stack[i] != self.tag_stack[i]):
                return False
        return True


    def handle_starttag(self, tag, attrs):
        if (tag != 'tr'):
            self.tag_stack.append(tag)

        if self.is_interested():
            if (tag == 'th' or tag == 'td'):
                self.data_num = self.data_num + 1


    def handle_data(self, data):
        # the line feed symbol will also be presented as data, we should ignore it
        if (data == "\n"):
            return

        if self.is_interested():
            if (self.data_num > 0):
                cve[keys[self.data_num - 1]] = str(data).strip()
                if (self.data_num == 13):
                    self.data_num = 0
                    cve2 = copy.deepcopy(cve)
                    cves.append(cve2)


    def handle_endtag(self, tag):
        if (tag != 'tr'):
            self.tag_stack.pop()


def parse_and_construct_cves(url):
    page = urllib.urlopen(url)
    html = page.read()
    parser = WrlCveHTMLParser()
    parser.feed(html)

print 'executing parse_and_construct_cves()'  # trace

parse_and_construct_cves(WRL_CVE_URL)


#===============================================================================

packages = []


def get_packages(file_name):
    package_set = set()
    file = open(file_name)
    for line in file.readlines():
        line = line.strip('\n')
        package_set.add(line)

    pkgs = list(package_set)

    pkgs.sort()

    file.close()

    return pkgs


print 'executing get_packages()'  # trace

packages = get_packages(PACKAGE_LIST_FILE)

print packages  # trace



#===============================================================================
# filter cves

def is_interested_version(version):
    ver_list = version.split('.')
    if ver_list == ['']:
        return True

    if int(ver_list[3]) < 14:
        return False
    else:
        return True

def is_interested_ack_date(date):
    date_list = date.split('-')
    if (int(date_list[0]) > int('2014') and
        int(date_list[1]) > int('04') and
        int(date_list[2]) > int('15')):
        return True
    else:
        return False

def is_one_of_substring(cve):
    for pkg in packages:
        if (pkg in cve["Package"]):
            return True
    return False


def is_interested_package(cve):
    if (is_one_of_substring(cve) and
        cve["Status"] != "Not Applicable" and
        cve["Status"] != "Won't Fix" and
        cve["Status"] != "Duplicate" and
        is_interested_ack_date(cve["ACK"])):
        return True
    else:
        return False

n_packs = 0
cves_result = []
for cve in cves:
    if (is_interested_package(cve)):
        n_packs = n_packs + 1
        cves_result.append(copy.deepcopy(cve))

print 'total:', n_packs, 'packages'  # trace

#===============================================================================


cves_result.sort(key=lambda x: x['Number'])

print "cves_result size: ", len(cves_result)



#===============================================================================

class CveDetailHTMLParser(HTMLParser):
    data_num = 0
    tag_stack = []
    target_tag_stack = ['html', 'body', 'form', 'div', 'div', 'div', 'table', 'tr', 'td', 'div', 'p']
    closer_tags = ['html', 'body', 'form', 'div', 'script',
                   'map', 'ul', 'li', 'a', 'dl', 'dt', 'dd',
                   'strong', 'p', 'span', 'h1', 'h2', 'h3',
                   'h4', 'h5', 'h6', 'h7', 'h8', 'table',
                   'thread', 'tbody', 'pre', 'th', 'tr', 'td']
    start_work = False;

    def __init__(self, cve):
        HTMLParser.__init__(self)
        self.cve = cve
    def is_interested(self):
        if (len(self.tag_stack) != len(self.target_tag_stack)):
            return False

        for i in range(len(self.target_tag_stack)):
            if (self.target_tag_stack[i] != self.tag_stack[i]):
                return False
        return True

    def is_closer_tag(self, tag):
        if tag in self.closer_tags:
            return True
        else:
            return False

    def handle_starttag(self, tag, attrs):
        if self.is_closer_tag(tag):
            self.tag_stack.append(tag)

        if tag == 'div' and ('class', 'vulnDetail') in attrs:
            self.start_work = True

    def handle_data(self, data):
        if self.start_work and self.is_interested():
            print self.cve
            print self.cve["Number"]  # trace
            print self.cve["URL"]  # trace
            self.cve["Description"] = data
            print self.cve["Description"]  # trace

    def is_work_deep(self):
        sck = ['html', 'body', 'form', 'div', 'div', 'div', 'table', 'tr', 'td', 'div']
        if (len(self.tag_stack) != len(sck)):
            return False

        for i in range(len(sck)):
            if (sck[i] != self.tag_stack[i]):
                return False
        return True

    def handle_endtag(self, tag):
        if  tag == 'div' and self.start_work and self.is_work_deep():
            self.start_work = False
        if self.is_closer_tag(tag):
            self.tag_stack.pop()

def produce_description(cve):
    # add URL key-value to cve
    cve["URL"] = "https://web.nvd.nist.gov/view/vuln/detail?vulnId=" + cve["Number"]

    print cve["URL"]  # trace

    # add Description key-value to cve
    cve["Description"] = ''
    page = urllib.urlopen(cve["URL"])
    html = page.read()
    parser = CveDetailHTMLParser(cve)
    parser.feed(html)
    page.close()

def get_cve_description(cves_result):
    count = 1
    for cve in cves_result:
        print count, "..."
        count = count + 1
        produce_description(cve)



print "executing get_cve_description()"  # trace
get_cve_description(cves_result)






#===============================================================================

def generate_twiki_table_patchlist(cves_result):
    with open('twiki_table_patchlist.txt', 'w') as fd:
        for cve in cves_result:
            print >> fd, '|' + cve["Number"] + '|' + ' ' + '|' + "http://web.nvd.nist.gov/view/vuln/detail?vulnId=" + cve["Number"] + '|' + cve["Package"] + '|' + ' ' + '|'



def generate_twiki_table_for_execl(cves_result, xls_name='WRLinuxVERSION-CUSTOMER-CVE-List-YEARMONTH.xls'):
    import xlwt

    workbook = xlwt.Workbook(encoding='ascii')
    worksheet = workbook.add_sheet('sheet1')

    # write headers
    worksheet.write(0, 0, label='Number')
    worksheet.write(0, 1, label='Package')
    worksheet.write(0, 2, label='Priority')
    worksheet.write(0, 3, label='Description')
    worksheet.write(0, 4, label='URL')

    # write contents
    raw = 1
    for cve in cves_result:
        worksheet.write(raw, 0, label=cve["Number"])
        worksheet.write(raw, 1, label=cve["Package"])
        worksheet.write(raw, 2, label=cve["Priority"])
        worksheet.write(raw, 3, label=cve["Description"])
        worksheet.write(raw, 4, label=cve["URL"])
        raw = raw + 1

    workbook.save(xls_name)

for c in cves_result:
    print c

print "executing generate_twiki_table_for_execl()"  # trace
generate_twiki_table_for_execl(cves_result)

print "executing generate_twiki_table_patchlist()"  # trace
generate_twiki_table_patchlist(cves_result)
